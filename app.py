import logging
from src.chat_manager import ChatManager
from src.vectorstore_manager import ChromaDatabaseManager
from src.information_extractor_manager import InformationExtractor
from src.retriever_manager import RAGManager
from src.prompt_manager import PromptManager
import chainlit as cl
from langchain_chroma import Chroma

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

extractor = InformationExtractor()
prompt_manager = PromptManager()
chat_manager = ChatManager(prompt_manager=prompt_manager)
database_manager = ChromaDatabaseManager()


def initialize_database():
    """
       Initialize the database by checking if the collection exists and is filled.
       If not, create the embedding vectorstore.
    """
    logger.info("Checking if database collection exists and is filled...")
    if not database_manager.collection_exists_and_filled():
        logger.info("Creating embedding vectorstore...")
        database_manager.create_embedding_vectorstore()
    else:
        logger.info("Collection already exists and is filled with data.")


initialize_database()
database = database_manager.create_chroma_database()


@cl.on_chat_start
async def on_chat_start():
    """
        Initialize the chat session, set session variables, and send a welcome message.
    """
    logger.info("Chat started. Initializing session variables.")
    history = chat_manager.get_session_history()
    cl.user_session.set("database", database)
    cl.user_session.set("history", history)
    logger.info("Sending welcome message to user.")
    await cl.Message(content="I am a virtual gardening assistant. "
                             "I will help you choose the perfect plant for your garden. "
                             "Just help me determine what you’re looking for. "
                             "Let’s get started!").send()


@cl.on_message
async def main(message: cl.Message):
    """
        Handle incoming messages from the user, generate a response, and check if the conversation has ended.
    """
    logger.info(f"Received message from user: {message.content}")
    history = cl.user_session.get("history")
    response = chat_manager.get_response(user_input=message.content)
    logger.info(f"Generated response: {response}")
    if conversation_ended(response):
        logger.info("Conversation ended detected. Handling conversation end.")
        await handle_conversation_end(history, database)
        await end()
    else:
        logger.info("Sending response to user.")
        await cl.Message(content=response).send()


@cl.on_chat_end
async def end():
    """
        Send a thank you message when the chat ends.
    """
    logger.info("Chat ended. Sending thank you message.")
    await cl.Message(content="Thank you for conversation!").send()


def conversation_ended(response: str) -> bool:
    """
        Check if the conversation has ended based on the response content.

        Args:
            response (str): The response generated by the system.

        Returns:
            bool: True if the conversation has ended, otherwise False.
    """
    ended = "END OF CONVERSATION" in response
    logger.info(f"Checking if conversation ended: {ended}")
    return ended


async def handle_conversation_end(history: str, database: Chroma):
    """
        Handle the end of the conversation by extracting information, retrieving documents,
        generating a response, and sending plant details.

        Args:
            history (str): The chat history.
            database: The Chroma database instance.
    """
    plant_description = extractor.extract_informations_from_response(prompt_manager=prompt_manager,
                                                                     prompt_file_name="extract_informations_template",
                                                                     history=history)
    logger.info(f"Extracted plant description: {plant_description}")
    plant_groups = extractor.extract_plant_groups_from_response(prompt_manager=prompt_manager,
                                                                prompt_file_name="extract_plant_group_template",
                                                                history=history)
    logger.info(f"Extracted plant groups: {plant_groups}")
    rag_manager = RAGManager(prompt_manager=prompt_manager, vectorstore=database)
    retriever = rag_manager.create_retriever(plant_groups=plant_groups)
    retriever_docs = retriever.invoke(plant_description)
    logger.info(f"Retrieved documents: {[doc.page_content for doc in retriever_docs]}")
    response = rag_manager.get_response(plant_groups=plant_groups, plant_description=plant_description)
    logger.info(f"Response: {response}")
    dict_of_plants = extractor.extract_plant_names_and_image_paths(prompt_manager=prompt_manager,
                                                                   prompt_file_name="extract_dict", history=response)
    logger.info(f"Extracted plants from response: {dict_of_plants}")

    final_response = extractor.extract_informations_from_response(prompt_manager=prompt_manager,
                                                                  prompt_file_name="extract_final_response",
                                                                  history=response)
    logger.info(f"Final response generated: {final_response}")
    chat_manager.clear_session_history()
    logger.info("Cleared session history.")
    await cl.Message(content=final_response).send()
    for plant_name, image_path in dict_of_plants.items():
        if image_path != "9a58e99369a6799c9fc054c69935d7a509541b9e.jpg":
            image = cl.Image(path=f"data/images/{image_path}", display='inline', size='large', name='plant')
            await cl.Message(
                content=plant_name,
                elements=[image],
            ).send()
